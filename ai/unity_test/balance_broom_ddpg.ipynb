{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "class Memory:   # stored as ( s, a, r, s_ ) in SumTree\n",
    "\n",
    "    def __init__(self, capacity, e = 0.01, a = 0.6):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.capacity = capacity\n",
    "        self.size = 0\n",
    "        self.e = e # error\n",
    "        self.a = a # priority exponent, 0 = no priority\n",
    "\n",
    "    def _getPriority(self, error):\n",
    "        return (error + self.e) ** self.a\n",
    "\n",
    "    def add(self, sample, error):\n",
    "        p = self._getPriority(error)\n",
    "        self.tree.add(p, sample) \n",
    "        self.size += 1\n",
    "        if self.size > self.capacity:\n",
    "            self.size = self.capacity\n",
    "\n",
    "    def sample(self, n):\n",
    "        batch = []\n",
    "        segment = self.tree.total() / n\n",
    "\n",
    "        for i in range(n):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "\n",
    "            s = random.uniform(a, b)\n",
    "            (idx, _, data) = self.tree.get(s)\n",
    "            batch.append( (idx, data) )\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def update(self, idx, error):\n",
    "        p = self._getPriority(error)\n",
    "        self.tree.update(idx, p)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "class SumTree:\n",
    "    write = 0\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = numpy.zeros( 2*capacity - 1 )\n",
    "        self.data = numpy.zeros( capacity, dtype=object )\n",
    "\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "\n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s-self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    def add(self, p, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "\n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, p)\n",
    "\n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "\n",
    "    def update(self, idx, p):\n",
    "        change = p - self.tree[idx]\n",
    "\n",
    "        self.tree[idx] = p\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        dataIdx = idx - self.capacity + 1\n",
    "\n",
    "        return (idx, self.tree[idx], self.data[dataIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "class DDPGAgent:\n",
    "    def __init__(self, env, n_actions, n_features, action_low, action_high, featurize=False, reward_decay=0.95,\n",
    "                 actor_learning_rate=0.01, critic_learning_rate=0.01, learning_rate_decay=0.95,\n",
    "                 memory_size=10000, priority_alpha=0.6, tau=0.9, variance=3):\n",
    "        self.env = env\n",
    "        self.state_size = n_features\n",
    "        self.action_size = n_actions\n",
    "        self.action_low = action_low\n",
    "        self.action_high = action_high\n",
    "        self.gamma = reward_decay   # discount rate\n",
    "        self.actor_model_set = False\n",
    "        self.critic_model_set = False\n",
    "        self.actor_learning_rate = actor_learning_rate\n",
    "        self.critic_learning_rate = critic_learning_rate # often larger than actor_learning_rate\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.priority_alpha = priority_alpha\n",
    "        self.tau = tau # soft update\n",
    "        self.batch_size = 32\n",
    "        self.memory = Memory(capacity=memory_size, a=priority_alpha)\n",
    "        self.variance = variance # exploration\n",
    "        self.memory_size = memory_size\n",
    "        self.featurize = featurize\n",
    "        if featurize:\n",
    "            self._init_featurizer()\n",
    "        self._construct_nets()\n",
    "        \n",
    "    def _construct_nets(self):\n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.S = tf.placeholder(tf.float32, [None, self.state_size], 'state')\n",
    "        self.S_ = tf.placeholder(tf.float32, [None, self.state_size], 'next_state')\n",
    "        self.R = tf.placeholder(tf.float32, [None, 1], 'r')\n",
    "\n",
    "        with tf.variable_scope('Actor'):\n",
    "            self.a = self._build_a(self.S, scope='eval', trainable=True)\n",
    "            self.a_ = self._build_a(self.S_, scope='target', trainable=False)\n",
    "        with tf.variable_scope('Critic'):\n",
    "            # assign self.a = a in memory when calculating q for td_error,\n",
    "            # otherwise the self.a is from Actor when updating Actor\n",
    "            q = self._build_c(self.S, self.a, scope='eval', trainable=True)\n",
    "            q_ = self._build_c(self.S_, self.a_, scope='target', trainable=False)\n",
    "        \n",
    "        # networks parameters\n",
    "        self.ae_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Actor/eval')\n",
    "        self.at_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Actor/target')\n",
    "        self.ce_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Critic/eval')\n",
    "        self.ct_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Critic/target')\n",
    "\n",
    "        # target net replacement\n",
    "        self.soft_replace = [[tf.assign(ta, (1 - self.tau) * ta + self.tau * ea), tf.assign(tc, (1 - self.tau) * tc + self.tau * ec)]\n",
    "                             for ta, ea, tc, ec in zip(self.at_params, self.ae_params, self.ct_params, self.ce_params)]\n",
    "\n",
    "        q_target = self.R + self.gamma * q_\n",
    "        # in the feed_dic for the td_error, the self.a should change to actions in memory\n",
    "        self.td_error_element_wise = tf.squared_difference(q_target, q)\n",
    "        self.td_error = tf.losses.mean_squared_error(labels=q_target, predictions=q)\n",
    "        self.ctrain = tf.train.AdamOptimizer(self.critic_learning_rate).minimize(self.td_error, var_list=self.ce_params)\n",
    "           \n",
    "        a_loss = - tf.reduce_mean(q)    # maximize the q\n",
    "        self.atrain = tf.train.AdamOptimizer(self.actor_learning_rate).minimize(a_loss, var_list=self.ae_params)\n",
    "        \n",
    "        self.saver = tf.train.Saver() # saver\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _build_a(self, s, scope, trainable): # policy\n",
    "        with tf.variable_scope(scope):\n",
    "            net = tf.layers.dense(s, 200, activation=tf.nn.relu, name='l1', trainable=trainable)\n",
    "            net = tf.layers.dense(net, 100, activation=tf.nn.relu, name='l2', trainable=trainable)\n",
    "            net = tf.layers.dense(net, 30, activation=tf.nn.relu, name='l3', trainable=trainable)\n",
    "            a = tf.layers.dense(net, self.action_size, activation=tf.nn.tanh, name='a', trainable=trainable)\n",
    "            self.actor_model_set = True\n",
    "            return a * (self.action_high-self.action_low)/2 + (self.action_high+self.action_low)/2\n",
    "    \n",
    "    def _build_c(self, s, a, scope, trainable): # advantage value\n",
    "        with tf.variable_scope(scope):\n",
    "            n_l1 = 200\n",
    "            w1_s = tf.get_variable('w1_s', [self.state_size, n_l1], trainable=trainable)\n",
    "            w1_a = tf.get_variable('w1_a', [self.action_size, n_l1], trainable=trainable)\n",
    "            b1 = tf.get_variable('b1', [1, n_l1], trainable=trainable)\n",
    "            net = tf.nn.relu(tf.matmul(s, w1_s) + tf.matmul(a, w1_a) + b1)\n",
    "            net = tf.layers.dense(net, 100, activation=tf.nn.relu, name='l2', trainable=trainable)\n",
    "            net = tf.layers.dense(net, 30, activation=tf.nn.relu, name='l3', trainable=trainable)\n",
    "            self.critic_model_set = True\n",
    "            return tf.layers.dense(net, 1, trainable=trainable)  # Q(s,a)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        if self.priority_alpha > 0: # prioritised\n",
    "            self.memory.add((state, action, reward, next_state, done), \n",
    "                            self.error(state, action, reward, next_state))\n",
    "        else: # non prioritised, every memory has priority 1\n",
    "            self.memory.add((state, action, reward, next_state, done), 1)\n",
    "            \n",
    "    def error(self, state, action, reward, next_state):\n",
    "        return self.sess.run(self.td_error, {self.S: state, self.a: [action], \n",
    "                                             self.R: [[reward]], self.S_: next_state})\n",
    "        \n",
    "    def choose_action(self, state, variance, low, high): # normal distribution\n",
    "        assert self.actor_model_set, 'actor model not set!'\n",
    "        action = self.sess.run(self.a, {self.S: state})[0]\n",
    "        return np.clip(np.random.normal(action, variance), low, high)\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        assert self.actor_model_set, 'model not set!'\n",
    "        assert self.critic_model_set, 'critic model not set!'\n",
    "        minibatch = self.memory.sample(batch_size)\n",
    "        idxs, states, actions, rewards, next_states = [], [], [], [], []\n",
    "        for idx, (state, action, reward, next_state, _) in minibatch:\n",
    "            idxs+=[idx]\n",
    "            states+=[state]\n",
    "            actions+=[action]\n",
    "            rewards+=[reward]\n",
    "            next_states+=[next_state]\n",
    "        \n",
    "        self.sess.run(self.atrain, {self.S: np.vstack(states)})\n",
    "        self.sess.run(self.ctrain, {self.S: np.vstack(states), self.a: np.vstack(actions),\n",
    "                                    self.R: np.vstack(rewards), self.S_: np.vstack(next_states)})\n",
    "        self.sess.run(self.soft_replace) # update the weights\n",
    "        \n",
    "        if self.priority_alpha > 0: # prioritised, update\n",
    "            errors = self.sess.run(self.td_error_element_wise, {self.S: np.vstack(states), self.a: np.vstack(actions),\n",
    "                                                                self.R: np.vstack(rewards), self.S_: np.vstack(next_states)})\n",
    "            for i in range(len(idxs)):\n",
    "                self.memory.update(idxs[i], errors[i])\n",
    "        \n",
    "        self.actor_learning_rate *= self.learning_rate_decay\n",
    "        self.critic_learning_rate *= self.learning_rate_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from numpy import newaxis\n",
    "\n",
    "METHOD = [\n",
    "    dict(name='kl_pen', kl_target=0.01, lam=0.5),   # KL penalty\n",
    "    dict(name='clip', epsilon=0.2),                 # Clipped surrogate objective, find this is better\n",
    "][1]        # choose the method for optimization\n",
    "\n",
    "class PPOTest:\n",
    "    def __init__(self, env:gym.Env, n_actions, n_features, action_low, action_high, featurize=False, reward_decay=0.95,\n",
    "                 actor_learning_rate=0.01, critic_learning_rate=0.01, learning_rate_decay=0.95,\n",
    "                 tau=1.0):\n",
    "        self.env = env\n",
    "        self.state_size = n_features\n",
    "        self.action_size = n_actions\n",
    "        self.action_low = action_low\n",
    "        self.action_high = action_high\n",
    "        self.gamma = reward_decay   # discount rate\n",
    "        self.actor_model_set = True\n",
    "        self.critic_model_set = True\n",
    "        self.actor_learning_rate = actor_learning_rate\n",
    "        self.critic_learning_rate = critic_learning_rate # often larger than actor_learning_rate\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.tau = tau # soft update\n",
    "        self.batch_size = 32\n",
    "        self.memory = [] # store (s, a, r)\n",
    "        self.featurize = featurize\n",
    "        if featurize:\n",
    "            self._init_featurizer()\n",
    "        self._construct_nets()\n",
    "        \n",
    "    def _construct_nets(self):\n",
    "        self.sess = tf.Session()\n",
    "        self.tfs = tf.placeholder(tf.float32, [None, self.state_size], 'state')\n",
    "\n",
    "        # critic\n",
    "        with tf.variable_scope('critic'):\n",
    "            l1 = tf.layers.dense(self.tfs, 200, tf.nn.relu)\n",
    "            l2 = tf.layers.dense(l1, 100, tf.nn.relu)\n",
    "            l3 = tf.layers.dense(l2, 30, tf.nn.relu)\n",
    "            self.v = tf.layers.dense(l3, 1)\n",
    "            self.tfdc_r = tf.placeholder(tf.float32, [None, 1], 'discounted_r')\n",
    "            self.advantage = self.tfdc_r - self.v\n",
    "            self.closs = tf.reduce_mean(tf.square(self.advantage))\n",
    "            self.ctrain_op = tf.train.AdamOptimizer(self.critic_learning_rate).minimize(self.closs)\n",
    "\n",
    "        # actor\n",
    "        pi, pi_params = self._build_anet('pi', trainable=True)\n",
    "        oldpi, oldpi_params = self._build_anet('oldpi', trainable=False)\n",
    "        with tf.variable_scope('sample_action'):\n",
    "            self.sample_op = tf.squeeze(pi.sample(1), axis=0)       # choosing action\n",
    "        with tf.variable_scope('update_oldpi'):\n",
    "            self.update_oldpi_op = [oldp.assign(p) for p, oldp in zip(pi_params, oldpi_params)]\n",
    "\n",
    "        self.tfa = tf.placeholder(tf.float32, [None, self.action_size], 'action')\n",
    "        self.tfadv = tf.placeholder(tf.float32, [None, 1], 'advantage')\n",
    "        with tf.variable_scope('loss'):\n",
    "            with tf.variable_scope('surrogate'):\n",
    "#                 ratio = tf.exp(pi.log_prob(self.tfa) - oldpi.log_prob(self.tfa))\n",
    "                ratio = pi.prob(self.tfa) / (oldpi.prob(self.tfa)+1e-10)\n",
    "                surr = ratio * self.tfadv\n",
    "            if METHOD['name'] == 'kl_pen':\n",
    "                self.tflam = tf.placeholder(tf.float32, None, 'lambda')\n",
    "                kl = tf.distributions.kl_divergence(oldpi, pi)\n",
    "                self.kl_mean = tf.reduce_mean(kl)\n",
    "                self.aloss = -(tf.reduce_mean(surr - self.tflam * kl))\n",
    "            else:   # clipping method, find this is better\n",
    "                self.aloss = -tf.reduce_mean(tf.minimum(\n",
    "                    surr,\n",
    "                    tf.clip_by_value(ratio, 1.-METHOD['epsilon'], 1.+METHOD['epsilon'])*self.tfadv))\n",
    "\n",
    "        with tf.variable_scope('atrain'):\n",
    "            self.atrain_op = tf.train.AdamOptimizer(self.actor_learning_rate).minimize(self.aloss)\n",
    "            \n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def _build_anet(self, name, trainable):\n",
    "        with tf.variable_scope(name):\n",
    "            l1 = tf.layers.dense(self.tfs, 200, tf.nn.relu, trainable=trainable)\n",
    "            l2 = tf.layers.dense(l1, 100, tf.nn.relu)\n",
    "            l3 = tf.layers.dense(l2, 30, tf.nn.relu)\n",
    "            mu = max(np.abs(self.action_low), np.abs(self.action_high)) * tf.layers.dense(l3, self.action_size, tf.nn.tanh, trainable=trainable)\n",
    "            sigma = tf.layers.dense(l3, self.action_size, tf.nn.softplus, trainable=trainable)\n",
    "            norm_dist = tf.distributions.Normal(loc=mu, scale=sigma+1e-5)\n",
    "        params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=name)\n",
    "        return norm_dist, params\n",
    "    \n",
    "    def choose_action(self, state): # normal distribution\n",
    "        assert self.actor_model_set, 'actor model not set!'\n",
    "        a = self.sess.run(self.sample_op, {self.tfs: state})[0]\n",
    "        return np.clip(a, self.action_low, self.action_high)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory += [[state[0], action, reward, next_state[0]]]\n",
    "    \n",
    "    def replay(self):\n",
    "        assert self.actor_model_set, 'model not set!'\n",
    "        assert self.critic_model_set, 'critic model not set!'\n",
    "        memory = np.vstack(self.memory)\n",
    "        states = np.vstack(memory[:,0])\n",
    "        actions = np.vstack(memory[:,1])\n",
    "        rewards = memory[:,2]\n",
    "        last_next_state = memory[:,3][-1]\n",
    "        \n",
    "        discounted_ep_rs = np.zeros_like(rewards)\n",
    "        running_add = self.sess.run(self.v, {self.tfs: [last_next_state]})[0]\n",
    "        for t in reversed(range(0, len(memory))):\n",
    "            running_add = running_add * self.gamma + rewards[t]\n",
    "            discounted_ep_rs[t] = running_add\n",
    "        \n",
    "        self.sess.run(self.update_oldpi_op)\n",
    "        adv = self.sess.run(self.advantage, {self.tfs: states, self.tfdc_r: discounted_ep_rs[:, newaxis]})\n",
    "        [self.sess.run(self.atrain_op, {self.tfs: states, self.tfa: actions, self.tfadv: adv}) for _ in range(10)]\n",
    "        [self.sess.run(self.ctrain_op, {self.tfs: states, self.tfdc_r: discounted_ep_rs[:, newaxis]}) for _ in range(10)]\n",
    "        \n",
    "        self.actor_learning_rate *= self.learning_rate_decay\n",
    "        self.critic_learning_rate *= self.learning_rate_decay\n",
    "        self.memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 8\n",
      "        Action space type: continuous\n",
      "        Action space size (per agent): 2\n",
      "        Memory space size (per agent): 0\n",
      "        Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "env_name = \"balance_broom\"\n",
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent state looks like: \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "train_mode = False\n",
    "    \n",
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "    \n",
    "# Examine the state space for the default brain\n",
    "print(\"Agent state looks like: \\n{}\".format(env_info.states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent = DDPGAgent(env,\n",
    "            n_actions=2,\n",
    "            n_features=8,\n",
    "            featurize=False, \n",
    "            action_high=1,\n",
    "            action_low=-1,\n",
    "            actor_learning_rate=0.0001,\n",
    "            critic_learning_rate=0.0002,\n",
    "            priority_alpha=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PPOTest(env,\n",
    "                n_actions=2,\n",
    "                n_features=8,\n",
    "                featurize=False, \n",
    "                action_high=1,\n",
    "                action_low=-1,\n",
    "                actor_learning_rate=0.0001,\n",
    "                critic_learning_rate=0.0002\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1786 rewards: -8.56 explore var: 1.547 rewards: -8.74 explore var: 3.00explore var: 3.00 81 rewards: -9.28 explore var: 3.00 121 rewards: -9.10 explore var: 3.00\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-079da25ed468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m0.999995\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-91cec228eead>\u001b[0m in \u001b[0;36mreplay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    121\u001b[0m         self.sess.run(self.ctrain, {self.S: np.vstack(states), self.a: np.vstack(actions),\n\u001b[0;32m    122\u001b[0m                                     self.R: np.vstack(rewards), self.S_: np.vstack(next_states)})\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoft_replace\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriority_alpha\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# prioritised, update\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#DDPG\n",
    "n_episodes = 3000\n",
    "\n",
    "# agent.saver.restore(agent.sess, \"model/model.ckpt\")\n",
    "rewards = []\n",
    "for i_episode in range(n_episodes):\n",
    "    env_info = agent.env.reset(train_mode=True)[default_brain]\n",
    "    state = env_info.states\n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action(state, agent.variance, agent.action_low, agent.action_high)\n",
    "        env_info = agent.env.step(action)[default_brain]\n",
    "        next_state = env_info.states\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        r += reward\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        # learn when memory is full, every BATCH steps\n",
    "        if len(agent.memory) == agent.memory_size:\n",
    "            agent.variance *= 0.999995\n",
    "            agent.replay(agent.batch_size)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, \"explore var: %.2f\" % agent.variance, end=\"\\r\")\n",
    "            rewards += [r]\n",
    "            break\n",
    "print(\"\\n\")\n",
    "print(\"finished learning!\")\n",
    "# agent.saver.save(agent.sess, \"model/model3g.ckpt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model3g_ppo.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-19 22:57:48,667] Restoring parameters from model/model3g_ppo.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 431 rewards: -6.9494 rewards: -7.98\r"
     ]
    }
   ],
   "source": [
    "# PPO\n",
    "n_episodes = 500\n",
    "\n",
    "agent.saver.restore(agent.sess, \"model/model3g_ppo.ckpt\")\n",
    "rewards = []\n",
    "for i_episode in range(n_episodes):\n",
    "    env_info = agent.env.reset(train_mode=True)[default_brain]\n",
    "    state = env_info.states\n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action(state)\n",
    "        env_info = agent.env.step(action)[default_brain]\n",
    "        next_state = env_info.states\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        r += reward\n",
    "        agent.remember(state, action, reward, next_state)\n",
    "        # learn when memory is full, every BATCH steps\n",
    "        if len(agent.memory) == agent.batch_size or done:\n",
    "            agent.replay()\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, end=\"\\r\")\n",
    "            rewards += [r]\n",
    "            break\n",
    "print(\"\\n\")\n",
    "print(\"finished learning!\")\n",
    "agent.saver.save(agent.sess, \"model/model3g_ppo.ckpt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d52fe47b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model3g.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model3g.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 16 rewards: -6.30\r"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d656fbf9d3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_low\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_high\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdefault_brain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\unityagents\\environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action, memory, value)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\"STEP\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\unityagents\\environment.py\u001b[0m in \u001b[0;36m_get_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_brains\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"brain_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mn_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"agents\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\site-packages\\unityagents\\environment.py\u001b[0m in \u001b[0;36m_get_state_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\"RECEIVED\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kwea123\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#ddpg\n",
    "n_episodes = 50\n",
    "\n",
    "test_rewards = []\n",
    "# agent.saver.restore(agent.sess, \"model/model3g.ckpt\")\n",
    "for i_episode in range(n_episodes):\n",
    "    env_info = agent.env.reset(train_mode=False)[default_brain]\n",
    "    state = env_info.states\n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action(state, 0, agent.action_low, agent.action_high)\n",
    "        env_info = agent.env.step(action)[default_brain]\n",
    "        next_state = env_info.states\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        r += reward\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, end=\"\\r\")\n",
    "            test_rewards += [r]\n",
    "            break\n",
    "print(\"\\n\")\n",
    "print(\"finished testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10 rewards: -5.86\n",
      "\n",
      "finished testing!\n"
     ]
    }
   ],
   "source": [
    "#ppo\n",
    "n_episodes = 10\n",
    "\n",
    "test_rewards = []\n",
    "# agent.saver.restore(agent.sess, \"model/model3g.ckpt\")\n",
    "for i_episode in range(n_episodes):\n",
    "    env_info = agent.env.reset(train_mode=False)[default_brain]\n",
    "    state = env_info.states\n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action(state)\n",
    "        env_info = agent.env.step(action)[default_brain]\n",
    "        next_state = env_info.states\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        r += reward\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, end=\"\\r\")\n",
    "            test_rewards += [r]\n",
    "            break\n",
    "print(\"\\n\")\n",
    "print(\"finished testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2972ae51710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.2215999999999987"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rewards[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.8572000000000006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.2800000000000127"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.3600000000000323"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
