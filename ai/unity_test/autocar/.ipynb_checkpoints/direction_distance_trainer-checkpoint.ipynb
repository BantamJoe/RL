{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('bounding_box_coordinates.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)\n",
    "    \n",
    "with open('distances.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_distance = Sequential()\n",
    "model_distance.add(Dense(32, input_dim=4, activation='relu'))\n",
    "model_distance.add(Dense(32, activation='relu'))\n",
    "model_distance.add(Dense(1))\n",
    "\n",
    "model_distance.compile(optimizer='adam',\n",
    "                       loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3381 samples, validate on 376 samples\n",
      "Epoch 1/100\n",
      "3381/3381 [==============================] - 2s - loss: 40.4920 - val_loss: 20.5205\n",
      "Epoch 2/100\n",
      "3381/3381 [==============================] - 0s - loss: 5.4221 - val_loss: 2.5454\n",
      "Epoch 3/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.4158 - val_loss: 2.5323\n",
      "Epoch 4/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.4038 - val_loss: 2.5166\n",
      "Epoch 5/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.3905 - val_loss: 2.4973\n",
      "Epoch 6/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.3788 - val_loss: 2.5282\n",
      "Epoch 7/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.3665 - val_loss: 2.5324\n",
      "Epoch 8/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.3498 - val_loss: 2.4416\n",
      "Epoch 9/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.3287 - val_loss: 2.4324\n",
      "Epoch 10/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.3123 - val_loss: 2.4391\n",
      "Epoch 11/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.2935 - val_loss: 2.4116\n",
      "Epoch 12/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.2731 - val_loss: 2.3819\n",
      "Epoch 13/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.2512 - val_loss: 2.3538\n",
      "Epoch 14/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.2296 - val_loss: 2.3292\n",
      "Epoch 15/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.2107 - val_loss: 2.3226\n",
      "Epoch 16/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.1786 - val_loss: 2.2665\n",
      "Epoch 17/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.1565 - val_loss: 2.2464\n",
      "Epoch 18/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.1212 - val_loss: 2.2032\n",
      "Epoch 19/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.1002 - val_loss: 2.2147\n",
      "Epoch 20/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.0604 - val_loss: 2.1484\n",
      "Epoch 21/100\n",
      "3381/3381 [==============================] - 0s - loss: 2.0270 - val_loss: 2.0992\n",
      "Epoch 22/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.9866 - val_loss: 2.1576\n",
      "Epoch 23/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.9403 - val_loss: 2.0460\n",
      "Epoch 24/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.8846 - val_loss: 2.0226\n",
      "Epoch 25/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.8358 - val_loss: 1.9194\n",
      "Epoch 26/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.7605 - val_loss: 1.8133\n",
      "Epoch 27/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.6862 - val_loss: 1.7233\n",
      "Epoch 28/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.5971 - val_loss: 1.6926\n",
      "Epoch 29/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.4865 - val_loss: 1.5174\n",
      "Epoch 30/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.3586 - val_loss: 1.3676\n",
      "Epoch 31/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.2193 - val_loss: 1.1892\n",
      "Epoch 32/100\n",
      "3381/3381 [==============================] - 0s - loss: 1.0104 - val_loss: 0.9524\n",
      "Epoch 33/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.7843 - val_loss: 0.7361\n",
      "Epoch 34/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.5567 - val_loss: 0.5280\n",
      "Epoch 35/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.3992 - val_loss: 0.4226\n",
      "Epoch 36/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.3217 - val_loss: 0.3580\n",
      "Epoch 37/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2840 - val_loss: 0.3550\n",
      "Epoch 38/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2739 - val_loss: 0.3427\n",
      "Epoch 39/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2587 - val_loss: 0.3141\n",
      "Epoch 40/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2530 - val_loss: 0.3125\n",
      "Epoch 41/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2533 - val_loss: 0.3056\n",
      "Epoch 42/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2474 - val_loss: 0.3024\n",
      "Epoch 43/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2401 - val_loss: 0.3084\n",
      "Epoch 44/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2377 - val_loss: 0.2984\n",
      "Epoch 45/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2334 - val_loss: 0.3015\n",
      "Epoch 46/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2319 - val_loss: 0.2872\n",
      "Epoch 47/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2321 - val_loss: 0.2868\n",
      "Epoch 48/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2238 - val_loss: 0.2843\n",
      "Epoch 49/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2295 - val_loss: 0.2856\n",
      "Epoch 50/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2274 - val_loss: 0.2894\n",
      "Epoch 51/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2273 - val_loss: 0.2833\n",
      "Epoch 52/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2212 - val_loss: 0.2973\n",
      "Epoch 53/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2260 - val_loss: 0.2990\n",
      "Epoch 54/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2259 - val_loss: 0.2863\n",
      "Epoch 55/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2200 - val_loss: 0.2856\n",
      "Epoch 56/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2176 - val_loss: 0.2805\n",
      "Epoch 57/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2211 - val_loss: 0.2810\n",
      "Epoch 58/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2205 - val_loss: 0.2795\n",
      "Epoch 59/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2214 - val_loss: 0.3053\n",
      "Epoch 60/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2193 - val_loss: 0.2856\n",
      "Epoch 61/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2140 - val_loss: 0.2848\n",
      "Epoch 62/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2132 - val_loss: 0.2832\n",
      "Epoch 63/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2153 - val_loss: 0.2833\n",
      "Epoch 64/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2189 - val_loss: 0.2859\n",
      "Epoch 65/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2127 - val_loss: 0.2780\n",
      "Epoch 66/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2170 - val_loss: 0.2848\n",
      "Epoch 67/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2107 - val_loss: 0.2752\n",
      "Epoch 68/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2101 - val_loss: 0.2952\n",
      "Epoch 69/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2156 - val_loss: 0.3104\n",
      "Epoch 70/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2151 - val_loss: 0.2735\n",
      "Epoch 71/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2124 - val_loss: 0.2738\n",
      "Epoch 72/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2090 - val_loss: 0.2838\n",
      "Epoch 73/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2114 - val_loss: 0.2860\n",
      "Epoch 74/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2128 - val_loss: 0.2723\n",
      "Epoch 75/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2091 - val_loss: 0.2719\n",
      "Epoch 76/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2046 - val_loss: 0.2929\n",
      "Epoch 77/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2086 - val_loss: 0.2893\n",
      "Epoch 78/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2051 - val_loss: 0.2708\n",
      "Epoch 79/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2098 - val_loss: 0.2754\n",
      "Epoch 80/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2044 - val_loss: 0.2708\n",
      "Epoch 81/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2041 - val_loss: 0.2691\n",
      "Epoch 82/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2048 - val_loss: 0.2783\n",
      "Epoch 83/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2014 - val_loss: 0.2769\n",
      "Epoch 84/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2010 - val_loss: 0.2680\n",
      "Epoch 85/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1997 - val_loss: 0.2725\n",
      "Epoch 86/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2009 - val_loss: 0.2979\n",
      "Epoch 87/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2072 - val_loss: 0.2680\n",
      "Epoch 88/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2068 - val_loss: 0.2656\n",
      "Epoch 89/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2009 - val_loss: 0.2654\n",
      "Epoch 90/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2046 - val_loss: 0.2660\n",
      "Epoch 91/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2003 - val_loss: 0.2854\n",
      "Epoch 92/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2005 - val_loss: 0.2657\n",
      "Epoch 93/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1959 - val_loss: 0.2673\n",
      "Epoch 94/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.2029 - val_loss: 0.2633ss: \n",
      "Epoch 95/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1991 - val_loss: 0.2751\n",
      "Epoch 96/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1980 - val_loss: 0.2904\n",
      "Epoch 97/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1955 - val_loss: 0.2655\n",
      "Epoch 98/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1980 - val_loss: 0.2759\n",
      "Epoch 99/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1979 - val_loss: 0.2640\n",
      "Epoch 100/100\n",
      "3381/3381 [==============================] - 0s - loss: 0.1938 - val_loss: 0.2613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34214f7eb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_distance.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x7f3420ff3978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAGoCAYAAADmTPpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGJSIiCgw/j9K6afNb8803gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3420ff3940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(model_distance.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_distance.save('model/model_distance.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fce144effd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAD8CAYAAACchf2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce1c0639b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "IMG_SIZE = (20,40)\n",
    "\n",
    "img = cv2.imread('human_imgs/0_5281.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, IMG_SIZE)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 20, 3)\n",
      "[[[ 0.60784314  0.60784314  0.50196078]\n",
      "  [ 0.76078431  0.59215686  0.49411765]\n",
      "  [ 0.77647059  0.69411765  0.59215686]\n",
      "  ..., \n",
      "  [ 0.85882353  0.98823529  1.        ]\n",
      "  [ 0.90196078  0.98431373  0.96862745]\n",
      "  [ 0.87843137  0.98823529  0.99607843]]\n",
      "\n",
      " [[ 0.79215686  0.67843137  0.60392157]\n",
      "  [ 0.80784314  0.67843137  0.62745098]\n",
      "  [ 0.80392157  0.69803922  0.60392157]\n",
      "  ..., \n",
      "  [ 0.85882353  0.94117647  0.94901961]\n",
      "  [ 0.84705882  0.94901961  0.95294118]\n",
      "  [ 0.84705882  0.94901961  0.95294118]]\n",
      "\n",
      " [[ 0.77647059  0.59215686  0.44313725]\n",
      "  [ 0.79215686  0.6627451   0.56470588]\n",
      "  [ 0.78823529  0.69803922  0.64313725]\n",
      "  ..., \n",
      "  [ 0.79215686  0.91372549  0.92156863]\n",
      "  [ 0.79215686  0.91372549  0.92156863]\n",
      "  [ 0.81176471  0.90588235  0.91372549]]\n",
      "\n",
      " ..., \n",
      " [[ 0.61568627  0.61176471  0.59607843]\n",
      "  [ 0.61960784  0.61568627  0.6       ]\n",
      "  [ 0.63137255  0.63137255  0.61176471]\n",
      "  ..., \n",
      "  [ 0.60392157  0.61568627  0.56862745]\n",
      "  [ 0.57647059  0.58823529  0.55294118]\n",
      "  [ 0.58039216  0.56862745  0.54901961]]\n",
      "\n",
      " [[ 0.61176471  0.60784314  0.58823529]\n",
      "  [ 0.63137255  0.63137255  0.61568627]\n",
      "  [ 0.65490196  0.65098039  0.63529412]\n",
      "  ..., \n",
      "  [ 0.57254902  0.57254902  0.57647059]\n",
      "  [ 0.56470588  0.54901961  0.51764706]\n",
      "  [ 0.56470588  0.54901961  0.53333333]]\n",
      "\n",
      " [[ 0.6         0.59607843  0.57647059]\n",
      "  [ 0.58431373  0.58039216  0.56470588]\n",
      "  [ 0.53333333  0.52941176  0.50980392]\n",
      "  ..., \n",
      "  [ 0.59215686  0.57254902  0.58039216]\n",
      "  [ 0.61176471  0.61568627  0.58823529]\n",
      "  [ 0.62352941  0.60784314  0.59607843]]]\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "print(img/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = []\n",
    "angles = []\n",
    "directions = []\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "angle_thr = 30\n",
    "for jpg in os.listdir('human_imgs/'):\n",
    "    img = cv2.imread('human_imgs/'+jpg)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = img/255\n",
    "    imgs += [img[np.newaxis, :]]\n",
    "    angle = int(jpg.split('_')[0])\n",
    "    angles += [angle]\n",
    "    direction = np.zeros((4))\n",
    "    if angle > angle_thr and angle < 180 - angle_thr:\n",
    "        direction[3] = 1\n",
    "    elif angle > 180 + angle_thr and angle < 360 - angle_thr:\n",
    "        direction[1] = 1\n",
    "    if angle > 90 + angle_thr and angle < 270 - angle_thr:\n",
    "        direction[0] = 1\n",
    "    elif angle < 90 - angle_thr or angle > 270 + angle_thr:\n",
    "        direction[2] = 1\n",
    "    directions += [direction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9654, 40, 20, 3)\n",
      "(9654, 1)\n",
      "(9654, 4)\n"
     ]
    }
   ],
   "source": [
    "imgs = np.vstack(imgs)\n",
    "angles = np.vstack(angles)\n",
    "directions = np.vstack(directions)\n",
    "print(imgs.shape)\n",
    "print(angles.shape)\n",
    "print(directions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_train, img_test, angle_train, angle_test, direction_train, direction_test = train_test_split(imgs, angles, directions, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 40, 20, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 20, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 20, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 20, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 10, 5, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 10, 5, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 10, 5, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 5, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 5, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               1311232   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 2,216,324\n",
      "Trainable params: 2,215,428\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_direction = Sequential()\n",
    "model_direction.add(Conv2D(64, (5,5), strides=(1,1), padding='same', input_shape=(40, 20, 3)))\n",
    "model_direction.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_direction.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model_direction.add(Conv2D(128, (3,3), strides=(1,1), padding='same'))\n",
    "model_direction.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_direction.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model_direction.add(Conv2D(256, (3,3), strides=(1,1), padding='same'))\n",
    "model_direction.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_direction.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model_direction.add(Flatten())\n",
    "model_direction.add(Dense(512, activation='relu'))\n",
    "model_direction.add(Dropout(0.5))\n",
    "model_direction.add(Dense(1024, activation='relu'))\n",
    "model_direction.add(Dropout(0.5))\n",
    "model_direction.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "model_direction.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8688 samples, validate on 966 samples\n",
      "Epoch 1/10\n",
      "8688/8688 [==============================] - 2s - loss: 0.0498 - acc: 0.9822 - val_loss: 0.1476 - val_acc: 0.9542\n",
      "Epoch 2/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0480 - acc: 0.9823 - val_loss: 0.1625 - val_acc: 0.9568\n",
      "Epoch 3/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0392 - acc: 0.9866 - val_loss: 0.1643 - val_acc: 0.9638\n",
      "Epoch 4/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0323 - acc: 0.9883 - val_loss: 0.1418 - val_acc: 0.9656\n",
      "Epoch 5/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0262 - acc: 0.9904 - val_loss: 0.1529 - val_acc: 0.9689\n",
      "Epoch 6/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0246 - acc: 0.9909 - val_loss: 0.2478 - val_acc: 0.9441\n",
      "Epoch 7/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0224 - acc: 0.9917 - val_loss: 0.3121 - val_acc: 0.9273\n",
      "Epoch 8/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0261 - acc: 0.9915 - val_loss: 0.3213 - val_acc: 0.9371\n",
      "Epoch 9/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0235 - acc: 0.9925 - val_loss: 0.1138 - val_acc: 0.9710\n",
      "Epoch 10/10\n",
      "8688/8688 [==============================] - 1s - loss: 0.0217 - acc: 0.9926 - val_loss: 0.1055 - val_acc: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd74b09c88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_direction.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "model_direction.fit(img_train, direction_train, epochs=10, batch_size=128, validation_data=(img_test, direction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_direction.save_weights('model/model_direction_lowres_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_direction.load_weights('model/model_direction_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_direction.predict(img_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96706587,  0.96482412,  0.95547945,  0.96176471])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(direction_test, preds, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  1.  1.]\n",
      " [ 1.  0.  0.  1.]]\n",
      "[[ 75]\n",
      " [106]\n",
      " [159]\n",
      " [176]\n",
      " [ 14]\n",
      " [253]\n",
      " [142]\n",
      " [133]\n",
      " [ 47]\n",
      " [129]]\n"
     ]
    }
   ],
   "source": [
    "print(preds[:10])\n",
    "print(angle_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _bn_relu(inputs):\n",
    "    \"\"\"\n",
    "    BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(inputs)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu(filters, kernel_size=(3, 3), strides=(1, 1)):\n",
    "    \"\"\"\n",
    "    conv -> BN -> relu\n",
    "    \"\"\"\n",
    "    def f(inputs):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                      padding='same', kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(inputs)\n",
    "        norm = BatchNormalization(axis=CHANNEL_AXIS)(conv)\n",
    "        return Activation(\"relu\")(norm)\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv(filters, kernel_size=(3, 3), strides=(1, 1)):\n",
    "    \"\"\"\n",
    "    BN -> relu -> conv\n",
    "    \"\"\"\n",
    "    def f(inputs):\n",
    "        norm = BatchNormalization(axis=CHANNEL_AXIS)(inputs)\n",
    "        activation = Activation(\"relu\")(norm)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                      padding='same', kernel_initializer=\"he_normal\", kernel_regularizer=l2(1e-4))(activation)\n",
    "    return f\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"\n",
    "    basic residual block : 3*3 kernel\n",
    "    \"\"\"\n",
    "    def f(inputs):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(inputs)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters, (3, 3), strides=init_strides)(inputs)\n",
    "        residual = _bn_relu_conv(filters, (3, 3))(conv1)\n",
    "        return _shortcut(inputs, residual)\n",
    "    return f\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"\n",
    "    bottleneck : 1*1 filters -> 3*3 filters -> 1*1 4*filters\n",
    "    \"\"\"\n",
    "    def f(inputs):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(inputs)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(inputs)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(inputs, residual)\n",
    "    return f\n",
    "\n",
    "def _shortcut(inputs, residual):\n",
    "    input_shape = K.int_shape(inputs)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = residual._keras_shape[CHANNEL_AXIS] == inputs._keras_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = inputs\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual._keras_shape[CHANNEL_AXIS], kernel_size=(1, 1), strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\", kernel_initializer=\"he_normal\")(inputs)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    def f(inputs):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            inputs = block_function(filters=filters, init_strides=init_strides,\n",
    "                                    is_first_block_of_first_layer=(is_first_layer and i == 0))(inputs)\n",
    "        return inputs\n",
    "    return f\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_rows, nb_cols, nb_channels)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        assert input_shape[-1] == 3, 'must use channel_last format!'\n",
    "        global ROW_AXIS, COL_AXIS, CHANNEL_AXIS\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "        \n",
    "        inputs = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(inputs)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\", activation='sigmoid')(flatten1)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_res = ResnetBuilder.build_resnet_18(img_train[0].shape, 4)\n",
    "model_res.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8688 samples, validate on 966 samples\n",
      "Epoch 1/10\n",
      "8688/8688 [==============================] - 17s - loss: 0.4669 - acc: 0.9403 - val_loss: 0.4608 - val_acc: 0.8929\n",
      "Epoch 2/10\n",
      "8688/8688 [==============================] - 14s - loss: 0.2218 - acc: 0.9609 - val_loss: 0.6278 - val_acc: 0.8300\n",
      "Epoch 3/10\n",
      "8688/8688 [==============================] - 13s - loss: 0.1661 - acc: 0.9678 - val_loss: 3.2019 - val_acc: 0.5828\n",
      "Epoch 4/10\n",
      "8688/8688 [==============================] - 14s - loss: 0.1442 - acc: 0.9699 - val_loss: 1.9427 - val_acc: 0.6928\n",
      "Epoch 5/10\n",
      "8688/8688 [==============================] - 14s - loss: 0.1331 - acc: 0.9726 - val_loss: 0.1696 - val_acc: 0.9565\n",
      "Epoch 6/10\n",
      "8688/8688 [==============================] - 13s - loss: 0.1195 - acc: 0.9743 - val_loss: 0.1709 - val_acc: 0.9578\n",
      "Epoch 7/10\n",
      "8688/8688 [==============================] - 13s - loss: 0.1060 - acc: 0.9783 - val_loss: 1.2767 - val_acc: 0.7953\n",
      "Epoch 8/10\n",
      "8688/8688 [==============================] - 14s - loss: 0.1029 - acc: 0.9791 - val_loss: 0.3063 - val_acc: 0.9125\n",
      "Epoch 9/10\n",
      "8688/8688 [==============================] - 14s - loss: 0.0988 - acc: 0.9797 - val_loss: 0.1366 - val_acc: 0.9643\n",
      "Epoch 10/10\n",
      "8688/8688 [==============================] - 13s - loss: 0.0928 - acc: 0.9807 - val_loss: 0.1456 - val_acc: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd65395fe80>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res.fit(img_train, direction_train, epochs=10, batch_size=32, validation_data=(img_test, direction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_res.predict(img_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.93623188,  0.95718654,  0.88848263,  0.94930876])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(direction_test, preds, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_res.save_weights('model/model_direction_res18_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
