{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import newaxis\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PPOAgent:\n",
    "    def __init__(self, env, n_actions, n_features, action_low=-1, action_high=1, reward_decay=0.99,\n",
    "                 actor_learning_rate=0.01, critic_learning_rate=0.01, learning_rate_decay=0.95,\n",
    "                 ):\n",
    "        self.env = env\n",
    "        self.state_size = n_features\n",
    "        self.action_size = n_actions\n",
    "        self.action_low = action_low\n",
    "        self.action_high = action_high\n",
    "        self.gamma = reward_decay   # discount rate\n",
    "        self.actor_model_set = True\n",
    "        self.critic_model_set = True\n",
    "        self.actor_learning_rate = actor_learning_rate\n",
    "        self.critic_learning_rate = critic_learning_rate # often larger than actor_learning_rate\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.batch_size = 64\n",
    "        self.epsilon = 0.2 # used to clip\n",
    "        self.entfact = 2e-2 # entropy factor, to encourage exploration\n",
    "        self.lam = 0.95 # gae factor\n",
    "        self.memory = [] # store (s, a, r) for one agent\n",
    "        self.agents = 5 # number of agents that collect memory\n",
    "        self.history = {} # store the memory for different agents\n",
    "        self.history['states'] = []\n",
    "        self.history['actions'] = []\n",
    "        self.history['discounted_rs'] = []\n",
    "        self.history['advantages'] = []\n",
    "        self._construct_nets()\n",
    "        \n",
    "    def _construct_nets(self):\n",
    "        self.sess = tf.Session()\n",
    "        self.tfs = tf.placeholder(tf.float32, [None, self.state_size], 'state')\n",
    "\n",
    "        # critic\n",
    "        with tf.variable_scope('critic'):\n",
    "            net = tf.layers.dense(self.tfs, 128, tf.nn.relu)\n",
    "#             net = tf.layers.dense(net, 64, tf.nn.relu)\n",
    "#             net = tf.layers.dense(net, 32, tf.nn.relu)\n",
    "            self.v = tf.layers.dense(net, 1)\n",
    "            self.tfdc_r = tf.placeholder(tf.float32, [None, 1], 'discounted_r')\n",
    "            self.closs = tf.reduce_mean(tf.square(self.tfdc_r - self.v))\n",
    "            self.ctrain_op = tf.train.AdamOptimizer(self.critic_learning_rate).minimize(self.closs)\n",
    "\n",
    "        # actor\n",
    "        pi, pi_params = self._build_anet('pi', trainable=True)\n",
    "        test_pi = tf.distributions.Normal(loc=pi.mean(), scale=tf.zeros_like(pi.stddev()))\n",
    "        oldpi, oldpi_params = self._build_anet('oldpi', trainable=False)\n",
    "        with tf.variable_scope('sample_action'):\n",
    "            self.sample_op = tf.squeeze(pi.sample(1), axis=0)       # choosing action\n",
    "            self.sample_test = tf.squeeze(test_pi.sample(1), axis=0) # deterministic action in test\n",
    "        with tf.variable_scope('update_oldpi'):\n",
    "            self.update_oldpi_op = [oldp.assign(p) for p, oldp in zip(pi_params, oldpi_params)]\n",
    "\n",
    "        self.tfa = tf.placeholder(tf.float32, [None, self.action_size], 'action')\n",
    "        self.tfadv = tf.placeholder(tf.float32, [None, 1], 'advantage')\n",
    "        with tf.variable_scope('loss'):\n",
    "            with tf.variable_scope('surrogate'):\n",
    "                self.ratio = pi.prob(self.tfa) / (oldpi.prob(self.tfa)+1e-10)\n",
    "                surr = self.ratio * self.tfadv\n",
    "                surr2 = tf.clip_by_value(self.ratio, 1-self.epsilon, 1+self.epsilon) * self.tfadv\n",
    "                self.aloss = - tf.reduce_mean(tf.minimum(surr, surr2)) - self.entfact * tf.reduce_mean(pi.entropy())\n",
    "\n",
    "        with tf.variable_scope('atrain'):\n",
    "            self.atrain_op = tf.train.AdamOptimizer(self.actor_learning_rate).minimize(self.aloss, var_list=pi_params)\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def _build_anet(self, name, trainable):\n",
    "        with tf.variable_scope(name):\n",
    "            net = tf.layers.dense(self.tfs, 128, tf.nn.relu, trainable=trainable)\n",
    "#             net = tf.layers.dense(net, 64, tf.nn.relu, trainable=trainable)\n",
    "#             net = tf.layers.dense(net, 32, tf.nn.relu, trainable=trainable)\n",
    "            mu = max(np.abs(self.action_low), np.abs(self.action_high)) * tf.layers.dense(net, self.action_size, tf.nn.tanh, trainable=trainable)\n",
    "            sigma = tf.layers.dense(net, self.action_size, tf.nn.softplus, trainable=trainable)\n",
    "            norm_dist = tf.distributions.Normal(loc=mu, scale=sigma)\n",
    "        params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=name)\n",
    "        return norm_dist, params\n",
    "    \n",
    "    def choose_action(self, state, train=True): # normal distribution\n",
    "        assert self.actor_model_set, 'actor model not set!'\n",
    "        if train:\n",
    "            a = self.sess.run(self.sample_op, {self.tfs: state})[0]\n",
    "        else:\n",
    "            a = self.sess.run(self.sample_test, {self.tfs: state})[0]\n",
    "        return np.clip(a, self.action_low, self.action_high)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory += [[state[0], action, reward, next_state[0]]]\n",
    "    \n",
    "    def discount_rewards(self, rewards, gamma, value_next=0.0):\n",
    "        discounted_r = np.zeros_like(rewards)\n",
    "        running_add = value_next\n",
    "        for t in reversed(range(0, len(rewards))):\n",
    "            discounted_r[t] = running_add = running_add * gamma + rewards[t]\n",
    "        return discounted_r\n",
    "    \n",
    "    def process_memory(self):\n",
    "        memory = np.vstack(self.memory)\n",
    "        states = np.vstack(memory[:,0])\n",
    "        actions = np.vstack(memory[:,1])\n",
    "        rewards = memory[:,2]\n",
    "        last_next_state = memory[:,3][-1]\n",
    "        discounted_ep_rs = self.discount_rewards(rewards, self.gamma)[:, newaxis]\n",
    "#         value_estimates = self.sess.run(self.v, {self.tfs: states, self.obs: observations}).flatten()\n",
    "        value_estimates = self.sess.run(self.v, {self.tfs: np.r_[states, last_next_state[newaxis, :]]}).flatten()\n",
    "#         last_value_estimate = self.sess.run(self.v, {self.tfs: , self.obs: })[0]\n",
    "#         value_estimates = np.append(value_estimates, 0)\n",
    "        delta_t = rewards + self.gamma * value_estimates[1:] - value_estimates[:-1]\n",
    "        advs = self.discount_rewards(delta_t, self.gamma * self.lam)[:, newaxis] #gae\n",
    "        last = states.shape[0]\n",
    "        self.history['states'] += [states[-last:]]\n",
    "        self.history['actions'] += [actions[-last:]]\n",
    "        self.history['discounted_rs'] += [discounted_ep_rs[-last:]]\n",
    "        self.history['advantages'] += [advs[-last:]]\n",
    "        self.memory = [] # empty the memory\n",
    "    \n",
    "    def replay(self):\n",
    "        assert self.actor_model_set, 'model not set!'\n",
    "        assert self.critic_model_set, 'critic model not set!'\n",
    "        self.sess.run(self.update_oldpi_op)\n",
    "        \n",
    "        s = np.vstack(self.history['states'])\n",
    "        ac = np.vstack(self.history['actions'])\n",
    "        dc_r = np.vstack(self.history['discounted_rs'])\n",
    "        ad = np.vstack(self.history['advantages'])\n",
    "#         ad = (ad-ad.mean())/ad.std()\n",
    "        \n",
    "        for _ in range(10): # update K epochs\n",
    "            s, ac, dc_r, ad = shuffle(s, ac, dc_r, ad)\n",
    "            for l in range(s.shape[0]//self.batch_size):\n",
    "                start = l * self.batch_size\n",
    "                end = (l + 1) * self.batch_size\n",
    "                self.sess.run(self.atrain_op, {self.tfs: s[start:end], self.tfa: ac[start:end], self.tfadv: ad[start:end]})\n",
    "                self.sess.run(self.ctrain_op, {self.tfs: s[start:end], self.tfdc_r: dc_r[start:end]})\n",
    "            if s.shape[0] % self.batch_size != 0:\n",
    "                res = s.shape[0] % self.batch_size\n",
    "                self.sess.run(self.atrain_op, {self.tfs: s[-res:], self.tfa: ac[-res:], self.tfadv: ad[-res:]})\n",
    "                self.sess.run(self.ctrain_op, {self.tfs: s[-res:], self.tfdc_r: dc_r[-res:]})\n",
    "#         self.actor_learning_rate *= self.learning_rate_decay\n",
    "#         self.critic_learning_rate *= self.learning_rate_decay\n",
    "        \n",
    "        for key in self.history:\n",
    "            self.history[key] = [] # empty the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents.environment:\n",
      "'Academy' started successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 4\n",
      "        Action space type: continuous\n",
      "        Action space size (per agent): 2\n",
      "        Memory space size (per agent): 0\n",
      "        Action descriptions: , \n",
      "Agent state looks like: \n",
      "[ 0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "env_name = \"bipedal\"\n",
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]\n",
    "\n",
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=False)[default_brain]\n",
    "    \n",
    "# Examine the state space for the default brain\n",
    "print(\"Agent state looks like: \\n{}\".format(env_info.states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent = PPOAgent(env,\n",
    "                n_actions=2,\n",
    "                n_features=4,\n",
    "                action_high=1,\n",
    "                action_low=-1,\n",
    "                actor_learning_rate=1e-4,\n",
    "                critic_learning_rate=2e-4,\n",
    "                reward_decay=0.98\n",
    "                )\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1000 rewards: 123.76ewards: -28.18 rewards: -16.57 140 rewards: -7.68 226 rewards: -9.09 264 rewards: 0.37328 rewards: -8.14 350 rewards: -3.45 490 rewards: 21.39 492 rewards: 29.10 502 rewards: 22.67 527 rewards: 20.96 557 rewards: 24.53 567 rewards: 21.57\n",
      "\n",
      "finished learning!\n"
     ]
    }
   ],
   "source": [
    "# PPO\n",
    "n_episodes = 1000\n",
    "\n",
    "# agent.saver.restore(agent.sess, \"model/model_bipedal.ckpt\")\n",
    "for i_episode in range(n_episodes):\n",
    "    env_info = agent.env.reset(train_mode=True)[default_brain]\n",
    "    state = env_info.states\n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action(state)\n",
    "        env_info = agent.env.step(action)[default_brain]\n",
    "        next_state = env_info.states\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        r += reward\n",
    "        agent.remember(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, end=\"\\r\")\n",
    "            agent.process_memory()\n",
    "            rewards += [r]\n",
    "            break\n",
    "    if (i_episode+1) % agent.agents == 0: # update every n_agent episodes\n",
    "        agent.replay()\n",
    "    if (i_episode+1) % 100 == 0:\n",
    "        agent.saver.save(agent.sess, \"model/model_bipedal.ckpt\");\n",
    "print(\"\\n\")\n",
    "print(\"finished learning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model_bipedal.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model_bipedal.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 50 rewards: -36.45\n",
      "\n",
      "finished testing!\n"
     ]
    }
   ],
   "source": [
    "#ppo\n",
    "n_episodes = 50\n",
    "\n",
    "test_rewards = []\n",
    "agent.saver.restore(agent.sess, \"model/model_bipedal.ckpt\")\n",
    "for i_episode in range(n_episodes):\n",
    "    env_info = agent.env.reset(train_mode=False)[default_brain]\n",
    "    state = env_info.states\n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action(state, train=False)\n",
    "        env_info = agent.env.step(action)[default_brain]\n",
    "        next_state = env_info.states\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        r += reward\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, end=\"\\r\")\n",
    "            test_rewards += [r]\n",
    "            break\n",
    "print(\"\\n\")\n",
    "print(\"finished testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNBgopZRCg4FSSik0GCillAL+H95AHkopj1E9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203e3bda940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.2306714028\n"
     ]
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.show()\n",
    "print(np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
